{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a Dataset\n",
    "-------------------\n",
    "\n",
    "Here is an example of how to load the `Fashion-MNIST <https://research.zalando.com/project/fashion_mnist/fashion_mnist/>`_ dataset from TorchVision.\n",
    "Fashion-MNIST is a dataset of Zalando’s article images consisting of 60,000 training examples and 10,000 test examples.\n",
    "Each example comprises a 28×28 grayscale image and an associated label from one of 10 classes.\n",
    "\n",
    "We load the `FashionMNIST Dataset <https://pytorch.org/vision/stable/datasets.html#fashion-mnist>`_ with the following parameters:\n",
    " - ``root`` is the path where the train/test data is stored,\n",
    " - ``train`` specifies training or test dataset,\n",
    " - ``download=True`` downloads the data from the internet if it's not available at ``root``.\n",
    " - ``transform`` and ``target_transform`` specify the feature and label transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894c4ede6b884642b29b013180a43ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fdbaf71c0f444b8f10f3d1822e438d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23373d2fccb4d71878a2b440d47f311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a6d77e5b0745d68a162b58a78e5f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"fmnist\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"fmnist\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating and Visualizing the Dataset\n",
    "-----------------\n",
    "\n",
    "We can index ``Datasets`` manually like a list: ``training_data[index]``.\n",
    "We use ``matplotlib`` to visualize some samples in our training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each item is a couple of image data and a label - GRAY IMAGE\n",
    "img, label = training_data[1]\n",
    "np.array(img.squeeze()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_names = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle-Boot\",\n",
    "}\n",
    "# Create a function to show an image and try to save an image\n",
    "def create_image(data_image):\n",
    "    '''\n",
    "    data_image: an image with label from torch dataset\n",
    "    '''\n",
    "    img, label = data_image\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    # We use jpg format.\n",
    "    filename = labels_names[label]+'.jpg'\n",
    "    plt.imsave(filename, np.array(img.squeeze()), cmap='gray')\n",
    "    print('Image file name: ',filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image file name:  Coat.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAReklEQVR4nO3dbWxVZbYH8P+yUBGovFMqIIWJAcEIo4hXh9xgzJ04xAQnJgaiE2400/kwY4ZkPozxfhg/eBNzc2fmTqKZpHM1w9xwnWDGFz4YHYZMImN0QjFcBN+KpDCtpaVQbYvy1q77obumavdax7PPOXvX9f8lTduz+vQ87PbPOT1rP/sRVQURffNdkfcEiKg2GHaiIBh2oiAYdqIgGHaiIKbU8s5EhC/9V8H06dNTa/PmzTPHTp061axPmWL/ioyMjJRd7+/vN8d6dZqYqspEt2cKu4jcBeA3AOoA/LeqPpHl+31TXXGF/QTKC4xn9erVqbXt27ebYxcsWGDWFy5caNY/++wzs/7pp5+m1nbv3m2Ofe6558y6R2TC33kAQMSWc9lP40WkDsBTAL4HYDWAbSKS/ltHRLnK8jf7BgDHVPW4ql4E8EcAWyozLSKqtCxhXwzgH+M+70xu+wIRaRGRNhFpy3BfRJRR1V+gU9VWAK0AX6AjylOWR/YuAEvHfb4kuY2ICihL2A8AuE5ElotIPYCtAPZUZlpEVGmSpQUhIpsB/BdGW2/PqOq/O1//jXwab7V4gOq3eazW3fnz582xfX19Zt0bX1dXZ9anTZuWWrvyyivNsXfffbdZf/PNN826xZv38PBw2d87b1Xps6vqywBezvI9iKg2eLosURAMO1EQDDtREAw7URAMO1EQDDtREJn67F/7zr6hfXbPkiVLzPqOHTvM+v3332/WrWWkDQ0N5tj6+nqzPmvWLLN+9uxZs26dA+D1+L2lv8ePHzfrW7duTa2dO3fOHDuZpfXZ+chOFATDThQEw04UBMNOFATDThQEw04UBFtvFfDAAw+Y9ccff9yse1ef9dpEly9fTq2tXLnSHPviiy+a9SeffNKsP/XUU2Z90aJFqbWTJ0+aY71lqF5b0DouDz/8sDn2lVdeMetFxtYbUXAMO1EQDDtREAw7URAMO1EQDDtREAw7URDss5fIuuxxW5u9s5V3jC9evFjWnMZYO6necsst5liv171//36z7l3uubOzM7XW1NRkjvWWwF66dMmsz5gxo+yxN998s1nP+jOrJvbZiYJj2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYLItItrJGvWrEmtzZ492xzb399v1q1+MGBvewwAjY2NqbWDBw+aY2+88Uaz/uCDD5r1999/36xbl7keHBw0x3pbOnt1qxduHTMAuOOOO8z6q6++ataLKFPYRaQDwCCAYQCXVXV9JSZFRJVXiUf2O1TVPtWJiHLHv9mJgsgadgXwZxE5KCItE32BiLSISJuI2CeQE1FVZX0av1FVu0RkIYC9IvKeqr42/gtUtRVAKzC5F8IQTXaZHtlVtSt53wvgBQAbKjEpIqq8ssMuIjNEpGHsYwDfBXCkUhMjosrK8jS+EcALIjL2ff5XVSfvxbYda9euTa15ffDkGKXy+uze+I6OjtTahQsXzLFHjtj/P1977bVm3bum/cyZM1Nr3nbP3vdesWKFWbf67N5W1c3NzWZ9Mio77Kp6HEB6AoioUNh6IwqCYScKgmEnCoJhJwqCYScKgktcS3T77ben1rzLEntbMnstKG8pZ3d3t1m3WEtQAeCDDz4w6/Pnzy/7vr2lwd4yVGtLZo93ee9169aV/b2Lio/sREEw7ERBMOxEQTDsREEw7ERBMOxEQTDsREGwz16ilStXpta8PrvXJ/eWuHpLPZctW5Za83r83uWcvfFnzpwx69bcvB6/tRU14G+bPGVK+q/3yMiIOXbVqlVmfTLiIztREAw7URAMO1EQDDtREAw7URAMO1EQDDtREOyzl8haez08PGyO9frss2bNMutev9nqV3v9ZOtSzwAwdepUs37NNdeY9Z6entSad/7AwoULzfrVV19t1q3zH7zjYp0fMFnxkZ0oCIadKAiGnSgIhp0oCIadKAiGnSgIhp0oCPbZSzRnzpzUmreuuqGhwax7fXiv122t2/bWq/f395t1b7to674B4PXXX0+teT3666+/3qx71wEYGBhIrXk9fq8+GbmP7CLyjIj0isiRcbfNFZG9ItKevE9PAhEVQilP438P4K4v3fYIgH2qeh2AfcnnRFRgbthV9TUAX96faAuAncnHOwHcU9lpEVGllfs3e6Oqjm0wdgpA6qZcItICoKXM+yGiCsn8Ap2qqoik7pKnqq0AWgHA+joiqq5yW289ItIEAMn73spNiYiqodyw7wGwPfl4O4CXKjMdIqoW92m8iDwLYBOA+SLSCeAXAJ4AsFtEHgJwAsB91ZxkEVj7kHd2dppjvT75hQsXyprTGKsXPm3aNHOsNzdvD3TvuvJ1dXWptauuusocOzQ0lOm+rePirWefO3euWZ+M3LCr6raU0p0VngsRVRFPlyUKgmEnCoJhJwqCYScKgmEnCoJLXBNWiwiwW1TeMlCP13rzWlTWeFX7pEVv7vX19WbdO27Lly9Prd10003mWO8S2idOnDDrVrvU4y07Xrx4sVnv6uoq+76rhY/sREEw7ERBMOxEQTDsREEw7ERBMOxEQTDsREGwz57w+qZWPzprL9vbNvnYsWNm3VqGmmVbY8Cfu3eOgLXEdteuXebYW2+91awvXbrUrFtzy7I8FgDWrFlj1tlnJ6LcMOxEQTDsREEw7ERBMOxEQTDsREEw7ERBsM+eWLVqVdljs/Zse3p6zPobb7xh1jdu3Jhay3oOQNa1+tb933DDDebY/fv3m/V7773XrM+aNSu19vHHH5tjveO2bNkys15EfGQnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCoJ99kRzc7NZt9aMe9dO93rV7e3tZv3OO+0Nc637HxwcNMd616T3rt0+Y8YMsz4wMJBaW716tTnWW+d/+PBhs37bbbel1ryfibdls3fcish9ZBeRZ0SkV0SOjLvtMRHpEpFDydvm6k6TiLIq5Wn87wHcNcHtv1bVdcnby5WdFhFVmht2VX0NwNkazIWIqijLC3Q/EZHDydP8OWlfJCItItImIm0Z7ouIMio37L8F8C0A6wB0A/hl2heqaquqrlfV9WXeFxFVQFlhV9UeVR1W1REAvwOwobLTIqJKKyvsItI07tPvAziS9rVEVAxun11EngWwCcB8EekE8AsAm0RkHQAF0AHgR9WbYm0sWLCg7LFen31kZMSsL1q0yKx7e6SfP38+tWbtKw/4/WZvn3JvbtZ477h4x9Xrw/f29qbWZs+ebY711rNn+X3Jixt2Vd02wc1PV2EuRFRFPF2WKAiGnSgIhp0oCIadKAiGnSgILnFNzJ8/36wPDw+n1qZMsQ/jmTNnzLq1fBbwL3tstai8FpL17yql3tfXZ9atLaO95bPe3K1LRQPAuXPnUmtz5qSe4Q3A/3fPmzfPrBcRH9mJgmDYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmCfPeFdOtjqCXtbNns924sXL5p177LF1jJVa/kr4M/N6lUD/lJRawmst7w263bT1vJeb/nsJ598Yta9Pn0R8ZGdKAiGnSgIhp0oCIadKAiGnSgIhp0oCIadKAj22RNeL9vqN3uXW/Z6ut5aem876aNHj6bWvEs9e71q7xwC79/u9fkta9euNevd3d1mfWhoKLXm/Uy8eXvnZRQRH9mJgmDYiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmCfPeH1o6211d7WwQcOHDDrmzZtMutUnueffz61tmLFCnPswMCAWfe2wi4i95FdRJaKyF9F5B0ROSoiP01unysie0WkPXk/+VbzEwVSytP4ywB+pqqrAfwTgB+LyGoAjwDYp6rXAdiXfE5EBeWGXVW7VfWt5ONBAO8CWAxgC4CdyZftBHBPleZIRBXwtf5mF5FmAN8G8HcAjao6dnLyKQCNKWNaALRkmCMRVUDJr8aLyEwAfwKwQ1W/8OqFjr56NeErWKraqqrrVXV9ppkSUSYlhV1EpmI06LtUdewlzh4RaUrqTQB6qzNFIqoE92m8jK6BfBrAu6r6q3GlPQC2A3gief9SVWZYI9OmTSt7rLcM9OzZs2V/bypfe3t7as37mV26dMmse+OLqJS/2b8D4AcA3haRQ8ltj2I05LtF5CEAJwDcV5UZElFFuGFX1b8BSLvCwZ2VnQ4RVcvkey5CRGVh2ImCYNiJgmDYiYJg2ImC4BLXhHdJ5JGRkdSa13Pt7Owsa05jpkyxf0zWtstZ+8HepaY91tJgb0tmbxnphQsXzLp13LNs9wz422wXER/ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYJgnz1x+fJls271sr2e7UcffVTWnEpl9auteRed9zPxWMfd25LZOq8C8Hv8RcRHdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiAYdqIg2GdPZOmze2NPnTpV1pyiy7qW3lrL7/3MvOvGcz07ERUWw04UBMNOFATDThQEw04UBMNOFATDThREKfuzLwXwBwCNABRAq6r+RkQeA/BDAKeTL31UVV+u1kSrra+vz6w3Nzen1oaGhsyxx44dK2dKn6urqzPrWdd9F5V37Xbv3z19+vSy79tbz97f31/2985LKSfVXAbwM1V9S0QaABwUkb1J7deq+p/Vmx4RVUop+7N3A+hOPh4UkXcBLK72xIiosr7W3+wi0gzg2wD+ntz0ExE5LCLPiMiclDEtItImIm3ZpkpEWZQcdhGZCeBPAHao6gCA3wL4FoB1GH3k/+VE41S1VVXXq+r67NMlonKVFHYRmYrRoO9S1ecBQFV7VHVYVUcA/A7AhupNk4iycsMuo0uPngbwrqr+atztTeO+7PsAjlR+ekRUKaW8Gv8dAD8A8LaIHEpuexTANhFZh9F2XAeAH1VhfjXT0NBg1uvr61NrXovIu2yxx9vamL4+r53pbZPtbfFdRKW8Gv83ABMtLJ60PXWiiHgGHVEQDDtREAw7URAMO1EQDDtREAw7URC8lHSirc0+dX/x4vS1P6dPn06tAUBHR0c5U/pc1D571u2m33vvvdTahx9+mOl7nzx5MtP4PPCRnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSgIqWUPV0ROAzgx7qb5AOxrOOenqHMr6rwAzq1clZzbMlVdMFGhpmH/yp2LtBX12nRFnVtR5wVwbuWq1dz4NJ4oCIadKIi8w96a8/1bijq3os4L4NzKVZO55fo3OxHVTt6P7ERUIww7URC5hF1E7hKR90XkmIg8kscc0ohIh4i8LSKH8t6fLtlDr1dEjoy7ba6I7BWR9uT9hHvs5TS3x0SkKzl2h0Rkc05zWyoifxWRd0TkqIj8NLk912NnzKsmx63mf7OLSB2ADwD8C4BOAAcAbFPVd2o6kRQi0gFgvarmfgKGiPwzgCEAf1DVG5Lb/gPAWVV9IvmPco6q/rwgc3sMwFDe23gnuxU1jd9mHMA9AP4VOR47Y173oQbHLY9H9g0AjqnqcVW9COCPALbkMI/CU9XXAJz90s1bAOxMPt6J0V+WmkuZWyGoareqvpV8PAhgbJvxXI+dMa+ayCPsiwH8Y9znnSjWfu8K4M8iclBEWvKezAQaVbU7+fgUgMY8JzMBdxvvWvrSNuOFOXblbH+eFV+g+6qNqnoTgO8B+HHydLWQdPRvsCL1TkvaxrtWJthm/HN5Hrtytz/PKo+wdwFYOu7zJclthaCqXcn7XgAvoHhbUfeM7aCbvO/NeT6fK9I23hNtM44CHLs8tz/PI+wHAFwnIstFpB7AVgB7cpjHV4jIjOSFE4jIDADfRfG2ot4DYHvy8XYAL+U4ly8oyjbeaduMI+djl/v256pa8zcAmzH6ivyHAP4tjzmkzGsFgP9L3o7mPTcAz2L0ad0ljL628RCAeQD2AWgH8BcAcws0t/8B8DaAwxgNVlNOc9uI0afohwEcSt42533sjHnV5LjxdFmiIPgCHVEQDDtREAw7URAMO1EQDDtREAw7URAMO1EQ/w94ZKD4bPcYMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test our function by choose an image randomly\n",
    "random_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "create_image(training_data[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 48000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Create valid data\n",
    "valid_size = int(0.2 * len(training_data))\n",
    "train_size = int(0.8 * len(training_data))\n",
    "valid, train = random_split(training_data, [valid_size, train_size])\n",
    "print(len(valid), len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def write_images(dataset, dirname):\n",
    "    fullnames_list = []\n",
    "#     image_size = 32*32\n",
    "#     image_resolution = (32,32)\n",
    "#     data = np.array(df.drop(columns=['label', 'filename']))\n",
    "    # Create folder \n",
    "    if os.path.isdir(dirname) == False:\n",
    "        os.mkdir(dirname)\n",
    "    # create subfolder 0-> 9\n",
    "    for j in range(10):\n",
    "        newdir = dirname+'/'+str(j)\n",
    "        if os.path.isdir(newdir) == False:\n",
    "            os.mkdir(newdir)\n",
    "    count = [0 for j in range(10)]\n",
    "    \n",
    "    for n in range(len(dataset)):\n",
    "        img, label = dataset[n]\n",
    "        count[label] += 1\n",
    "        # Create filename\n",
    "        fullname = dirname + '/' + str(label) + '/' + labels_names[label] + '_' \n",
    "        # We use jpg format.\n",
    "        fullname += str(count[label]) + '.jpg'\n",
    "        fullnames_list.append(fullname)\n",
    "        \n",
    "        # write image file\n",
    "        image = np.array(img.squeeze())\n",
    "        plt.imsave(os.path.normpath(fullname), image, cmap='gray')\n",
    "    # create new column 'fullname' for dataframe \n",
    "    tmp = pd.DataFrame({'fullname': fullnames_list})\n",
    "#     tmp = pd.concat([tmp, df], axis=1)\n",
    "    return tmp\n",
    "# test function\n",
    "test_df = write_images(test_data, 'images/test')\n",
    "train_df = write_images(train, 'images/train')\n",
    "valid_df = write_images(valid, 'images/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 48000 12000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df), len(train_df), len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/test/9/Ankle-Boot_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/test/2/Pullover_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/test/1/Trouser_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/test/1/Trouser_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/test/6/Shirt_1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fullname\n",
       "0  images/test/9/Ankle-Boot_1.jpg\n",
       "1    images/test/2/Pullover_1.jpg\n",
       "2     images/test/1/Trouser_1.jpg\n",
       "3     images/test/1/Trouser_2.jpg\n",
       "4       images/test/6/Shirt_1.jpg"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1282\n",
       "9    1233\n",
       "1    1227\n",
       "6    1225\n",
       "2    1213\n",
       "4    1189\n",
       "8    1182\n",
       "7    1175\n",
       "5    1152\n",
       "0    1122\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to get label from fullname\n",
    "valid_df['label'] = valid_df['fullname'].apply(lambda x: x.split('/')[2])\n",
    "valid_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(df):\n",
    "    df['label'] = df['fullname'].apply(lambda x: int(x.split('/')[2]))\n",
    "    return df\n",
    "\n",
    "train_df = add_label(train_df)\n",
    "valid_df = add_label(valid_df)\n",
    "test_df = add_label(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   fullname  12000 non-null  object\n",
      " 1   label     12000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 187.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   fullname  10000 non-null  object\n",
      " 1   label     10000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48000 entries, 0 to 47999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   fullname  48000 non-null  object\n",
      " 1   label     48000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 750.1+ KB\n"
     ]
    }
   ],
   "source": [
    "valid_df.info()\n",
    "test_df.info()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filename list for later use\n",
    "def save_df2csv(df, csvname):\n",
    "    df.to_csv(csvname, index=False)\n",
    "\n",
    "save_df2csv(test_df, 'test.csv')\n",
    "save_df2csv(train_df, 'train.csv')\n",
    "save_df2csv(valid_df, 'valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have folder images with 3 subfolders train, valid, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwxr-xr-x 12 root root 6144 Feb  7 04:50 test\n",
      "drwxr-xr-x 12 root root 6144 Feb  7 04:53 train\n",
      "drwxr-xr-x 12 root root 6144 Feb  7 05:03 valid\n"
     ]
    }
   ],
   "source": [
    "! ls -l images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/test/9/Ankle-Boot_1.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/test/2/Pullover_1.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/test/1/Trouser_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/test/1/Trouser_2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/test/6/Shirt_1.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fullname  label\n",
       "0  images/test/9/Ankle-Boot_1.jpg      9\n",
       "1    images/test/2/Pullover_1.jpg      2\n",
       "2     images/test/1/Trouser_1.jpg      1\n",
       "3     images/test/1/Trouser_2.jpg      1\n",
       "4       images/test/6/Shirt_1.jpg      6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "testset = pd.read_csv('test.csv')\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    1000\n",
       "2    1000\n",
       "6    1000\n",
       "0    1000\n",
       "4    1000\n",
       "3    1000\n",
       "1    1000\n",
       "9    1000\n",
       "5    1000\n",
       "8    1000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset['label'] = testset['fullname'].apply(lambda x: x.split('/')[2])\n",
    "testset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_names = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coatadd_label\", \n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle-Boot\",\n",
    "}\n",
    "classes = pd.DataFrame({'class_name': labels_names})\n",
    "classes.to_csv('classes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "e64e21f9fcaa76da84f5df3b441923ec8eeafce976cee0ec61e060e722ca4042"
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
